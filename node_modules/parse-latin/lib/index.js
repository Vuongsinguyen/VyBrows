<<<<<<< HEAD
import {mergeInitialWordSymbol} from './plugin/merge-initial-word-symbol.js'
import {mergeFinalWordSymbol} from './plugin/merge-final-word-symbol.js'
import {mergeInnerWordSymbol} from './plugin/merge-inner-word-symbol.js'
import {mergeInnerWordSlash} from './plugin/merge-inner-word-slash.js'
import {mergeInitialisms} from './plugin/merge-initialisms.js'
import {mergeWords} from './plugin/merge-words.js'
import {patchPosition} from './plugin/patch-position.js'
import {mergeNonWordSentences} from './plugin/merge-non-word-sentences.js'
import {mergeAffixSymbol} from './plugin/merge-affix-symbol.js'
import {mergeInitialLowerCaseLetterSentences} from './plugin/merge-initial-lower-case-letter-sentences.js'
import {mergeInitialDigitSentences} from './plugin/merge-initial-digit-sentences.js'
import {mergePrefixExceptions} from './plugin/merge-prefix-exceptions.js'
import {mergeAffixExceptions} from './plugin/merge-affix-exceptions.js'
import {mergeRemainingFullStops} from './plugin/merge-remaining-full-stops.js'
import {makeInitialWhiteSpaceSiblings} from './plugin/make-initial-white-space-siblings.js'
import {makeFinalWhiteSpaceSiblings} from './plugin/make-final-white-space-siblings.js'
import {breakImplicitSentences} from './plugin/break-implicit-sentences.js'
import {removeEmptyNodes} from './plugin/remove-empty-nodes.js'
import {parserFactory} from './parser.js'
=======
/**
 * @typedef {import('nlcst').Nodes} Nodes
 * @typedef {import('nlcst').Parents} Parents
 * @typedef {import('nlcst').Paragraph} Paragraph
 * @typedef {import('nlcst').Root} Root
 * @typedef {import('nlcst').RootContent} RootContent
 * @typedef {import('nlcst').Sentence} Sentence
 * @typedef {import('nlcst').SentenceContent} SentenceContent
 * @typedef {import('vfile').VFile} VFile
 */

/**
 * @template {Nodes} Node
 *   Node type.
 * @callback Plugin
 *   Transform a node.
 * @param {Node} node
 *   The node.
 * @returns {undefined | void}
 *   Nothing.
 */

import {toString} from 'nlcst-to-string'
import {mergeAffixExceptions} from './plugin/merge-affix-exceptions.js'
import {mergeAffixSymbol} from './plugin/merge-affix-symbol.js'
import {breakImplicitSentences} from './plugin/break-implicit-sentences.js'
import {makeFinalWhiteSpaceSiblings} from './plugin/make-final-white-space-siblings.js'
import {makeInitialWhiteSpaceSiblings} from './plugin/make-initial-white-space-siblings.js'
import {mergeFinalWordSymbol} from './plugin/merge-final-word-symbol.js'
import {mergeInitialDigitSentences} from './plugin/merge-initial-digit-sentences.js'
import {mergeInitialLowerCaseLetterSentences} from './plugin/merge-initial-lower-case-letter-sentences.js'
import {mergeInitialWordSymbol} from './plugin/merge-initial-word-symbol.js'
import {mergeInitialisms} from './plugin/merge-initialisms.js'
import {mergeInnerWordSymbol} from './plugin/merge-inner-word-symbol.js'
import {mergeInnerWordSlash} from './plugin/merge-inner-word-slash.js'
import {mergeNonWordSentences} from './plugin/merge-non-word-sentences.js'
import {mergePrefixExceptions} from './plugin/merge-prefix-exceptions.js'
import {mergeRemainingFullStops} from './plugin/merge-remaining-full-stops.js'
import {removeEmptyNodes} from './plugin/remove-empty-nodes.js'
import {patchPosition} from './plugin/patch-position.js'
>>>>>>> 08f40ceb (Initial)
import {
  newLine,
  punctuation,
  surrogates,
  terminalMarker,
  whiteSpace,
  word
} from './expressions.js'

// PARSE LATIN

<<<<<<< HEAD
// Transform Latin-script natural language into an NLCST-tree.
export class ParseLatin {
  constructor(doc, file) {
    const value = file || doc
    this.doc = value ? String(value) : null
  }

  // Run transform plugins for `key` on `nodes`.
  run(key, nodes) {
    const wareKey = key + 'Plugins'
    const plugins = this[wareKey]
    let index = -1

    if (plugins) {
      while (plugins[++index]) {
        plugins[index](nodes)
      }
    }

    return nodes
  }

  // Easy access to the document parser. This additionally supports retext-style
  // invocation: where an instance is created for each file, and the file is given
  // on construction.
=======
/**
 * Create a new parser.
 */
export class ParseLatin {
  /**
   * Create a new parser.
   *
   * This additionally supports `retext`-like call: where an instance is
   * created for each file, and the file is given on construction.
   *
   * @param {string | null | undefined} [doc]
   *   Value to parse (optional).
   * @param {VFile | null | undefined} [file]
   *   Corresponding file (optional).
   */
  constructor(doc, file) {
    const value = file || doc

    /** @type {string | undefined} */
    this.doc = value ? String(value) : undefined

    /** @type {Array<Plugin<Root>>} */
    this.tokenizeRootPlugins = [...this.tokenizeRootPlugins]
    /** @type {Array<Plugin<Paragraph>>} */
    this.tokenizeParagraphPlugins = [...this.tokenizeParagraphPlugins]
    /** @type {Array<Plugin<Sentence>>} */
    this.tokenizeSentencePlugins = [...this.tokenizeSentencePlugins]
  }

  /**
   * Turn natural language into a syntax tree.
   *
   * @param {string | null | undefined} [value]
   *   Value to parse (optional).
   * @returns {Root}
   *   Tree.
   */
>>>>>>> 08f40ceb (Initial)
  parse(value) {
    return this.tokenizeRoot(value || this.doc)
  }

<<<<<<< HEAD
  // Transform a `value` into a list of `NLCSTNode`s.
  tokenize(value) {
    const tokens = []

    if (value === null || value === undefined) {
      value = ''
    } else if (value instanceof String) {
      value = value.toString()
    }

    if (typeof value !== 'string') {
      // Return the given nodes if this is either an empty array, or an array with
      // a node as a first child.
      if ('length' in value && (!value[0] || value[0].type)) {
        return value
      }

      throw new Error(
        "Illegal invocation: '" +
          value +
          "' is not a valid argument for 'ParseLatin'"
      )
    }

    if (!value) {
      return tokens
    }

    // Eat mechanism to use.
    const eater = this.position ? eat : noPositionEat

    let index = 0
    let offset = 0
    let line = 1
    let column = 1
    let previous = ''
    let queue = ''
    let left
    let right
    let character

    while (index < value.length) {
      character = value.charAt(index)

      if (whiteSpace.test(character)) {
        right = 'WhiteSpace'
      } else if (punctuation.test(character)) {
        right = 'Punctuation'
      } else if (word.test(character)) {
        right = 'Word'
      } else {
        right = 'Symbol'
      }

      tick.call(this)

      previous = character
      character = ''
      left = right
      right = null

      index++
    }

    tick.call(this)

    return tokens

    // Check one character.
    function tick() {
      if (
        left === right &&
        (left === 'Word' ||
          left === 'WhiteSpace' ||
          character === previous ||
          surrogates.test(character))
      ) {
        queue += character
      } else {
        // Flush the previous queue.
        if (queue) {
          this['tokenize' + left](queue, eater)
        }

        queue = character
      }
    }

    // Remove `subvalue` from `value`.
    // Expects `subvalue` to be at the start from `value`, and applies no
    // validation.
    function eat(subvalue) {
      const pos = position()

      update(subvalue)

      return apply

      // Add the given arguments, add `position` to the returned node, and return
      // the node.
      function apply(...input) {
        return pos(add(...input))
      }
    }

    // Remove `subvalue` from `value`.
    // Does not patch positional information.
    function noPositionEat() {
      return add
    }

    // Add mechanism.
    function add(node, parent) {
      if (parent) {
        parent.children.push(node)
      } else {
        tokens.push(node)
      }

      return node
    }

    // Mark position and patch `node.position`.
    function position() {
      const before = now()

      // Add the position to a node.
      function patch(node) {
        node.position = new Position(before)

        return node
      }

      return patch
    }

    // Update line and column based on `value`.
    function update(subvalue) {
      let character = -1
      let lastIndex = -1

      offset += subvalue.length

      while (++character < subvalue.length) {
        if (subvalue.charAt(character) === '\n') {
          lastIndex = character
          line++
        }
      }

      if (lastIndex < 0) {
        column += subvalue.length
      } else {
        column = subvalue.length - lastIndex
      }
    }

    // Store position information for a node.
    function Position(start) {
      this.start = start
      this.end = now()
    }

    // Get the current position.
    function now() {
      return {line, column, offset}
=======
  /**
   * Parse as a root.
   *
   * @param {string | null | undefined} [value]
   *   Value to parse (optional).
   * @returns {Root}
   *   Built tree.
   */
  tokenizeRoot(value) {
    const paragraph = this.tokenizeParagraph(value)
    /** @type {Root} */
    const result = {
      type: 'RootNode',
      children: splitNode(paragraph, 'WhiteSpaceNode', newLine)
    }

    let index = -1
    while (this.tokenizeRootPlugins[++index]) {
      this.tokenizeRootPlugins[index](result)
    }

    return result
  }

  /**
   * Parse as a paragraph.
   *
   * @param {string | null | undefined} [value]
   *   Value to parse (optional).
   * @returns {Paragraph}
   *   Built tree.
   */
  tokenizeParagraph(value) {
    const sentence = this.tokenizeSentence(value)
    /** @type {Paragraph} */
    const result = {
      type: 'ParagraphNode',
      children: splitNode(sentence, 'PunctuationNode', terminalMarker)
    }

    let index = -1
    while (this.tokenizeParagraphPlugins[++index]) {
      this.tokenizeParagraphPlugins[index](result)
    }

    return result
  }

  /**
   * Parse as a sentence.
   *
   * @param {string | null | undefined} [value]
   *   Value to parse (optional).
   * @returns {Sentence}
   *   Built tree.
   */
  tokenizeSentence(value) {
    const children = this.tokenize(value)
    /** @type {Sentence} */
    const result = {type: 'SentenceNode', children}

    let index = -1
    while (this.tokenizeSentencePlugins[++index]) {
      this.tokenizeSentencePlugins[index](result)
    }

    return result
  }

  /**
   *  Transform a `value` into a list of nlcsts.
   *
   * @param {string | null | undefined} [value]
   *   Value to parse (optional).
   * @returns {Array<SentenceContent>}
   *   Built sentence content.
   */
  tokenize(value) {
    /** @type {Array<SentenceContent>} */
    const children = []

    if (!value) {
      return children
    }

    const currentPoint = {line: 1, column: 1, offset: 0}
    let from = 0
    let index = 0
    let start = {...currentPoint}
    /** @type {SentenceContent['type'] | undefined} */
    let previousType
    /** @type {string | undefined} */
    let previous

    while (index < value.length) {
      const current = value.charAt(index)
      const currentType = whiteSpace.test(current)
        ? 'WhiteSpaceNode'
        : punctuation.test(current)
        ? 'PunctuationNode'
        : word.test(current)
        ? 'WordNode'
        : 'SymbolNode'

      if (
        from < index &&
        previousType &&
        currentType &&
        !(
          previousType === currentType &&
          // Words or white space continue.
          (previousType === 'WordNode' ||
            previousType === 'WhiteSpaceNode' ||
            // Same character of punctuation or symbol also continues.
            current === previous ||
            // Surrogates of  punctuation or symbol also continue.
            surrogates.test(current))
        )
      ) {
        // Flush the previous queue.
        children.push(createNode(previousType, value.slice(from, index)))
        from = index
        start = {...currentPoint}
      }

      if (current === '\r' || (current === '\n' && previous !== '\r')) {
        currentPoint.line++
        currentPoint.column = 1
      } else if (current !== '\n') {
        currentPoint.column++
      }

      currentPoint.offset++
      previousType = currentType
      previous = current
      index++
    }

    if (previousType && from < index) {
      children.push(createNode(previousType, value.slice(from, index)))
    }

    return children

    /**
     * @param {SentenceContent['type']} type
     *   Node type to build.
     * @param {string} value
     *   Value.
     * @returns {SentenceContent}
     *   Node.
     */
    function createNode(type, value) {
      return type === 'WordNode'
        ? {
            type: 'WordNode',
            children: [
              {
                type: 'TextNode',
                value,
                position: {start, end: {...currentPoint}}
              }
            ],
            position: {start, end: {...currentPoint}}
          }
        : {type, value, position: {start, end: {...currentPoint}}}
>>>>>>> 08f40ceb (Initial)
    }
  }
}

<<<<<<< HEAD
// Default position.
ParseLatin.prototype.position = true

// Create text nodes.
ParseLatin.prototype.tokenizeSymbol = createTextFactory('Symbol')
ParseLatin.prototype.tokenizeWhiteSpace = createTextFactory('WhiteSpace')
ParseLatin.prototype.tokenizePunctuation = createTextFactory('Punctuation')
ParseLatin.prototype.tokenizeSource = createTextFactory('Source')
ParseLatin.prototype.tokenizeText = createTextFactory('Text')

// Inject `plugins` to modifiy the result of the method at `key` on the operated
// on context.
ParseLatin.prototype.use = useFactory(function (context, key, plugins) {
  context[key] = context[key].concat(plugins)
})

// Inject `plugins` to modifiy the result of the method at `key` on the operated
// on context, before any other.
ParseLatin.prototype.useFirst = useFactory(function (context, key, plugins) {
  context[key] = plugins.concat(context[key])
})

// PARENT NODES
//
// All these nodes are `pluggable`: they come with a `use` method which accepts
// a plugin (`function(NLCSTNode)`).
// Every time one of these methods are called, the plugin is invoked with the
// node, allowing for easy modification.
//
// In fact, the internal transformation from `tokenize` (a list of words, white
// space, punctuation, and symbols) to `tokenizeRoot` (an NLCST tree), is also
// implemented through this mechanism.

// Create a `WordNode` with its children set to a single `TextNode`, its value
// set to the given `value`.
pluggable(ParseLatin, 'tokenizeWord', function (value, eat) {
  const add = (eat || noopEat)('')
  const parent = {type: 'WordNode', children: []}

  this.tokenizeText(value, eat, parent)

  return add(parent)
})

// Create a `SentenceNode` with its children set to `Node`s, their values set
// to the tokenized given `value`.
//
// Unless plugins add new nodes, the sentence is populated by `WordNode`s,
// `SymbolNode`s, `PunctuationNode`s, and `WhiteSpaceNode`s.
pluggable(
  ParseLatin,
  'tokenizeSentence',
  parserFactory({type: 'SentenceNode', tokenizer: 'tokenize'})
)

// Create a `ParagraphNode` with its children set to `Node`s, their values set
// to the tokenized given `value`.
//
// Unless plugins add new nodes, the paragraph is populated by `SentenceNode`s
// and `WhiteSpaceNode`s.
pluggable(
  ParseLatin,
  'tokenizeParagraph',
  parserFactory({
    type: 'ParagraphNode',
    delimiter: terminalMarker,
    delimiterType: 'PunctuationNode',
    tokenizer: 'tokenizeSentence'
  })
)

// Create a `RootNode` with its children set to `Node`s, their values set to the
// tokenized given `value`.
pluggable(
  ParseLatin,
  'tokenizeRoot',
  parserFactory({
    type: 'RootNode',
    delimiter: newLine,
    delimiterType: 'WhiteSpaceNode',
    tokenizer: 'tokenizeParagraph'
  })
)

// PLUGINS

ParseLatin.prototype.use('tokenizeSentence', [
=======
/**
 * List of transforms handling a sentence.
 */
ParseLatin.prototype.tokenizeSentencePlugins = [
>>>>>>> 08f40ceb (Initial)
  mergeInitialWordSymbol,
  mergeFinalWordSymbol,
  mergeInnerWordSymbol,
  mergeInnerWordSlash,
  mergeInitialisms,
<<<<<<< HEAD
  mergeWords,
  patchPosition
])

ParseLatin.prototype.use('tokenizeParagraph', [
=======
  patchPosition
]

/**
 * List of transforms handling a paragraph.
 */
ParseLatin.prototype.tokenizeParagraphPlugins = [
>>>>>>> 08f40ceb (Initial)
  mergeNonWordSentences,
  mergeAffixSymbol,
  mergeInitialLowerCaseLetterSentences,
  mergeInitialDigitSentences,
  mergePrefixExceptions,
  mergeAffixExceptions,
  mergeRemainingFullStops,
  makeInitialWhiteSpaceSiblings,
  makeFinalWhiteSpaceSiblings,
  breakImplicitSentences,
  removeEmptyNodes,
  patchPosition
<<<<<<< HEAD
])

ParseLatin.prototype.use('tokenizeRoot', [
=======
]

/**
 * List of transforms handling a root.
 */
ParseLatin.prototype.tokenizeRootPlugins = [
>>>>>>> 08f40ceb (Initial)
  makeInitialWhiteSpaceSiblings,
  makeFinalWhiteSpaceSiblings,
  removeEmptyNodes,
  patchPosition
<<<<<<< HEAD
])

// TEXT NODES

// Factory to create a `Text`.
function createTextFactory(type) {
  type += 'Node'

  return createText

  // Construct a `Text` from a bound `type`
  function createText(value, eat, parent) {
    if (value === null || value === undefined) {
      value = ''
    }

    return (eat || noopEat)(value)({type, value: String(value)}, parent)
  }
}

// Make a method “pluggable”.
function pluggable(Constructor, key, callback) {
  // Set a pluggable version of `callback` on `Constructor`.
  Constructor.prototype[key] = function (...input) {
    return this.run(key, callback.apply(this, input))
  }
}

// Factory to inject `plugins`. Takes `callback` for the actual inserting.
function useFactory(callback) {
  return use

  // Validate if `plugins` can be inserted.
  // Invokes the bound `callback` to do the actual inserting.
  function use(key, plugins) {
    // Throw if the method is not pluggable.
    if (!(key in this)) {
      throw new Error(
        'Illegal Invocation: Unsupported `key` for ' +
          '`use(key, plugins)`. Make sure `key` is a ' +
          'supported function'
      )
    }

    // Fail silently when no plugins are given.
    if (!plugins) {
      return
    }

    const wareKey = key + 'Plugins'

    // Make sure `plugins` is a list.
    plugins = typeof plugins === 'function' ? [plugins] : plugins.concat()

    // Make sure `wareKey` exists.
    if (!this[wareKey]) {
      this[wareKey] = []
    }

    // Invoke callback with the ware key and plugins.
    callback(this, wareKey, plugins)
  }
}

// Add mechanism used when text-tokenisers are called directly outside of the
// `tokenize` function.
function noopAdd(node, parent) {
  if (parent) {
    parent.children.push(node)
  }

  return node
}

// Eat and add mechanism without adding positional information, used when
// text-tokenisers are called directly outside of the `tokenize` function.
function noopEat() {
  return noopAdd
=======
]

/**
 * A function that splits one node into several nodes.
 *
 * @template {Parents} Node
 *   Node type.
 * @param {Node} node
 *   Node to split.
 * @param {RegExp} expression
 *   Split on this regex.
 * @param {Node['children'][number]['type']} childType
 *   Split this node type.
 * @returns {Array<Node>}
 *   The given node, split into several nodes.
 */
function splitNode(node, childType, expression) {
  /** @type {Array<Node>} */
  const result = []
  let index = -1
  let start = 0

  while (++index < node.children.length) {
    const token = node.children[index]

    if (
      index === node.children.length - 1 ||
      (token.type === childType && expression.test(toString(token)))
    ) {
      /** @type {Node} */
      // @ts-expect-error: fine
      const parent = {
        type: node.type,
        children: node.children.slice(start, index + 1)
      }

      const first = node.children[start]
      const last = token
      if (first.position && last.position) {
        parent.position = {
          start: first.position.start,
          end: last.position.end
        }
      }

      result.push(parent)
      start = index + 1
    }
  }

  return result
>>>>>>> 08f40ceb (Initial)
}
